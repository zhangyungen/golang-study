package tssync

import (
	"fmt"
	"sync"
	"sync/atomic"
	"testing"
	"time"
)

// ==================== å¯¹æ¯”å®ç°ï¼šåŸç”Ÿå…¨å±€é” ====================
type globalMutex struct {
	mu   sync.RWMutex
	data map[string]interface{}
}

func NewGlobalMutex() *globalMutex {
	return &globalMutex{
		data: make(map[string]interface{}),
	}
}

func (g *globalMutex) Lock(key string) {
	g.mu.Lock()
}

func (g *globalMutex) Unlock(key string) {
	g.mu.Unlock()
}

func (g *globalMutex) RLock(key string) {
	g.mu.RLock()
}

func (g *globalMutex) RUnlock(key string) {
	g.mu.RUnlock()
}

// ==================== å¯¹æ¯”å®ç°ï¼šåˆ†æ®µé” ====================
type shardedMutex struct {
	shards []*shard
	count  uint32
}

type shard struct {
	mu   sync.RWMutex
	data map[string]interface{}
}

func NewShardedMutex(shardCount uint32) *shardedMutex {
	sm := &shardedMutex{
		shards: make([]*shard, shardCount),
		count:  shardCount,
	}
	for i := range sm.shards {
		sm.shards[i] = &shard{
			data: make(map[string]interface{}),
		}
	}
	return sm
}

func (s *shardedMutex) getShard(key string) *shard {
	// ç®€å•çš„å“ˆå¸Œå‡½æ•°
	hash := uint32(0)
	for i := 0; i < len(key); i++ {
		hash = hash*31 + uint32(key[i])
	}
	return s.shards[hash%s.count]
}

func (s *shardedMutex) Lock(key string) {
	s.getShard(key).mu.Lock()
}

func (s *shardedMutex) Unlock(key string) {
	s.getShard(key).mu.Unlock()
}

func (s *shardedMutex) RLock(key string) {
	s.getShard(key).mu.RLock()
}

func (s *shardedMutex) RUnlock(key string) {
	s.getShard(key).mu.RUnlock()
}

// ==================== æ€§èƒ½æµ‹è¯•æ¡†æ¶ ====================
type testConfig struct {
	name        string
	goroutines  int
	operations  int
	keyCount    int
	readRatio   float64 // è¯»æ“ä½œæ¯”ä¾‹
	hotspotRate float64 // çƒ­ç‚¹keyè®¿é—®æ¯”ä¾‹
}

type testResult struct {
	name       string
	totalOps   int64
	successOps int64
	totalTime  time.Duration
	avgLatency time.Duration
	minLatency time.Duration
	maxLatency time.Duration
	qps        float64
}

// æ€§èƒ½æµ‹è¯•æ¥å£
type locker interface {
	Lock(key string)
	Unlock(key string)
	RLock(key string)
	RUnlock(key string)
}

func runPerformanceTest(locker locker, config testConfig) testResult {
	var totalOps, successOps int64
	var minLatency, maxLatency time.Duration
	var totalLatency time.Duration

	startTime := time.Now()
	var wg sync.WaitGroup

	// ç”Ÿæˆæµ‹è¯•keys
	keys := generateKeys(config.keyCount)

	// ç”¨äºç»Ÿè®¡çš„channel
	results := make(chan time.Duration, config.goroutines*config.operations)

	for i := 0; i < config.goroutines; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			localOps := int64(0)
			localSuccess := int64(0)

			for j := 0; j < config.operations; j++ {
				// é€‰æ‹©keyï¼ˆæ¨¡æ‹Ÿçƒ­ç‚¹è®¿é—®ï¼‰
				key := selectKey(keys, config.hotspotRate)

				opStart := time.Now()

				// æ ¹æ®è¯»å†™æ¯”ä¾‹æ‰§è¡Œæ“ä½œ
				if float64(j%100) < config.readRatio*100 {
					// è¯»æ“ä½œ
					locker.RLock(key)
					// æ¨¡æ‹Ÿè¯»æ“ä½œè€—æ—¶
					time.Sleep(10 * time.Nanosecond)
					locker.RUnlock(key)
					localSuccess++
				} else {
					// å†™æ“ä½œ
					locker.Lock(key)
					// æ¨¡æ‹Ÿå†™æ“ä½œè€—æ—¶
					time.Sleep(20 * time.Nanosecond)
					locker.Unlock(key)
					localSuccess++
				}

				latency := time.Since(opStart)
				results <- latency
				localOps++
			}

			atomic.AddInt64(&totalOps, localOps)
			atomic.AddInt64(&successOps, localSuccess)
		}(i)
	}

	wg.Wait()
	close(results)
	totalTime := time.Since(startTime)

	// å¤„ç†å»¶è¿Ÿç»Ÿè®¡
	var count int64
	for latency := range results {
		count++
		totalLatency += latency

		if count == 1 {
			minLatency = latency
			maxLatency = latency
		} else {
			if latency < minLatency {
				minLatency = latency
			}
			if latency > maxLatency {
				maxLatency = latency
			}
		}
	}

	avgLatency := time.Duration(0)
	if count > 0 {
		avgLatency = time.Duration(int64(totalLatency) / count)
	}

	return testResult{
		name:       config.name,
		totalOps:   totalOps,
		successOps: successOps,
		totalTime:  totalTime,
		avgLatency: avgLatency,
		minLatency: minLatency,
		maxLatency: maxLatency,
		qps:        float64(totalOps) / totalTime.Seconds(),
	}
}

func generateKeys(count int) []string {
	keys := make([]string, count)
	for i := 0; i < count; i++ {
		keys[i] = fmt.Sprintf("key%d", i)
	}
	return keys
}

func selectKey(keys []string, hotspotRate float64) string {
	// æ¨¡æ‹Ÿçƒ­ç‚¹è®¿é—®ï¼šéƒ¨åˆ†keyè¢«æ›´é¢‘ç¹åœ°è®¿é—®
	if hotspotRate > 0 && len(keys) > 10 {
		hotspotCount := int(float64(len(keys)) * hotspotRate)
		if hotspotCount < 1 {
			hotspotCount = 1
		}
		// 80%çš„è¯·æ±‚è®¿é—®å‰hotspotCountä¸ªkey
		return keys[int(float64(hotspotCount))]
	}
	// å‡åŒ€åˆ†å¸ƒ
	return keys[len(keys)/2]
}

// ==================== åŸºå‡†æµ‹è¯•å‡½æ•° ====================
func BenchmarkLockers(b *testing.B) {
	configs := []testConfig{
		{
			name:        "ä½å¹¶å‘-å¤škey",
			goroutines:  10,
			operations:  1000,
			keyCount:    100,
			readRatio:   0.8,
			hotspotRate: 0.1,
		},
		{
			name:        "é«˜å¹¶å‘-å°‘key",
			goroutines:  400,
			operations:  400,
			keyCount:    50,
			readRatio:   0.8,
			hotspotRate: 0.5,
		},
		{
			name:        "é«˜å¹¶å‘-å¤škey",
			goroutines:  100,
			operations:  400,
			keyCount:    100,
			readRatio:   0.9,
			hotspotRate: 0.1,
		},
		{
			name:        "å†™å¯†é›†-å¤škey",
			goroutines:  30,
			operations:  300,
			keyCount:    50,
			readRatio:   0.2,
			hotspotRate: 0.2,
		},
	}

	for _, config := range configs {
		b.Run(fmt.Sprintf("MiniMutex-%s", config.name), func(b *testing.B) {
			for i := 0; i < b.N; i++ {
				// åŒ…è£…miniMutexå®ç°lockeræ¥å£
				miniLocker := &miniMutexLocker{}
				runPerformanceTest(miniLocker, config)
			}
		})

		b.Run(fmt.Sprintf("GlobalMutex-%s", config.name), func(b *testing.B) {
			for i := 0; i < b.N; i++ {
				globalLocker := NewGlobalMutex()
				runPerformanceTest(globalLocker, config)
			}
		})

		b.Run(fmt.Sprintf("ShardedMutex-%s", config.name), func(b *testing.B) {
			for i := 0; i < b.N; i++ {
				shardedLocker := NewShardedMutex(32)
				runPerformanceTest(shardedLocker, config)
			}
		})
	}
}

// miniMutexçš„lockeræ¥å£é€‚é…å™¨
type miniMutexLocker struct{}

func (m *miniMutexLocker) Lock(key string) {
	Lock(key)
}

func (m *miniMutexLocker) Unlock(key string) {
	UnLock(key)
}

func (m *miniMutexLocker) RLock(key string) {
	// miniMutexæ²¡æœ‰åŒºåˆ†è¯»å†™é”ï¼Œä½¿ç”¨å†™é”ä»£æ›¿
	RLock(key)
}

func (m *miniMutexLocker) RUnlock(key string) {
	RUnlock(key)
}

// ==================== æ€§èƒ½å¯¹æ¯”æµ‹è¯• ====================
func TestPerformanceComparison(t *testing.T) {
	testScenarios := []testConfig{
		{
			name:        "è¯»å¤šå†™å°‘-ä½ç«äº‰",
			goroutines:  20,
			operations:  500,
			keyCount:    100,
			readRatio:   0.9,
			hotspotRate: 0.1,
		},
		{
			name:        "è¯»å†™å‡è¡¡-é«˜ç«äº‰",
			goroutines:  4000,
			operations:  1000,
			keyCount:    20,
			readRatio:   0.6,
			hotspotRate: 0.5,
		},
		{
			name:        "å†™å¯†é›†-ä¸­ç­‰ç«äº‰",
			goroutines:  2000,
			operations:  5000,
			keyCount:    30,
			readRatio:   0,
			hotspotRate: 0.5,
		},
	}

	fmt.Println("ğŸ”¬ é”æ€§èƒ½å¯¹æ¯”æµ‹è¯•ç»“æœ")
	fmt.Println("=" + repeatString("=", 78))

	for _, scenario := range testScenarios {
		fmt.Printf("\nğŸ“Š æµ‹è¯•åœºæ™¯: %s\n", scenario.name)
		fmt.Printf("é…ç½®: goroutines=%d, operations=%d, keys=%d, è¯»æ¯”ä¾‹=%.1f, çƒ­ç‚¹ç‡=%.1f\n",
			scenario.goroutines, scenario.operations, scenario.keyCount,
			scenario.readRatio, scenario.hotspotRate)

		// æµ‹è¯•ä¸‰ç§é”å®ç°
		miniLocker := &miniMutexLocker{}
		globalLocker := NewGlobalMutex()
		shardedLocker := NewShardedMutex(32)

		miniResult := runPerformanceTest(miniLocker, scenario)
		globalResult := runPerformanceTest(globalLocker, scenario)
		shardedResult := runPerformanceTest(shardedLocker, scenario)

		printResult("æ‚¨çš„ MiniMutex", miniResult)
		printResult("å…¨å±€é” GlobalMutex", globalResult)
		printResult("åˆ†æ®µé” ShardedMutex", shardedResult)

		// æ€§èƒ½å¯¹æ¯”åˆ†æ
		miniQPS := miniResult.qps
		globalQPS := globalResult.qps
		shardedQPS := shardedResult.qps

		fmt.Printf("\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”åˆ†æ:\n")
		fmt.Printf("MiniMutex ç›¸å¯¹äº GlobalMutex çš„æ€§èƒ½æå‡: %.2f%%\n",
			(miniQPS/globalQPS-1)*100)
		fmt.Printf("MiniMutex ç›¸å¯¹äº ShardedMutex çš„æ€§èƒ½å·®å¼‚: %.2f%%\n",
			(miniQPS/shardedQPS-1)*100)

		fmt.Println("â”€" + repeatString("â”€", 78))
	}
}

func printResult(name string, result testResult) {
	fmt.Printf("%-20s: QPS=%.0f, å¹³å‡å»¶è¿Ÿ=%-10v, æˆåŠŸç‡=%.1f%%, æ€»æ“ä½œ=%d\n",
		name, result.qps, result.avgLatency,
		float64(result.successOps)/float64(result.totalOps)*100,
		result.totalOps)
}

func repeatString(s string, n int) string {
	result := ""
	for i := 0; i < n; i++ {
		result += s
	}
	return result
}

// ==================== å¹¶å‘å®‰å…¨æµ‹è¯• ====================
func TestConcurrentSafety(t *testing.T) {
	fmt.Println("\nğŸ”’ å¹¶å‘å®‰å…¨æµ‹è¯•")

	// æµ‹è¯•æ•°æ®ç«äº‰
	const iterations = 10000
	key := "test_key"

	// ä½¿ç”¨miniMutexä¿æŠ¤å…±äº«è®¡æ•°å™¨
	counter := 0
	var wg sync.WaitGroup
	wg.Add(2)

	start := time.Now()

	go func() {
		defer wg.Done()
		for i := 0; i < iterations; i++ {
			Lock(key)
			counter++
			UnLock(key)
		}
	}()

	go func() {
		defer wg.Done()
		for i := 0; i < iterations; i++ {
			Lock(key)
			counter--
			UnLock(key)
		}
	}()

	wg.Wait()
	duration := time.Since(start)

	if counter != 0 {
		t.Errorf("âŒ å¹¶å‘å®‰å…¨æµ‹è¯•å¤±è´¥: æœŸæœ›counter=0, å®é™…counter=%d", counter)
	} else {
		fmt.Printf("âœ… å¹¶å‘å®‰å…¨æµ‹è¯•é€šè¿‡: æ“ä½œæ•°=%d, è€—æ—¶=%v, QPS=%.0f\n",
			iterations*2, duration, float64(iterations*2)/duration.Seconds())
	}
}

func main() {
	fmt.Println("ğŸš€ Goé”æ€§èƒ½å‹æµ‹å·¥å…·")
	fmt.Println()

	// è¿è¡Œæ€§èƒ½æµ‹è¯•
	testing.Main(func(pat, str string) (bool, error) { return true, nil },
		[]testing.InternalTest{
			{Name: "TestPerformanceComparison", F: TestPerformanceComparison},
			{Name: "TestConcurrentSafety", F: TestConcurrentSafety},
		},
		[]testing.InternalBenchmark{
			{Name: "BenchmarkLockers", F: BenchmarkLockers},
		},
		nil)
}
